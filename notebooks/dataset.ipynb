{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ultralytics opencv-python yt-dlp  # Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736275de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import SAM\n",
    "\n",
    "# --- Configuration ---\n",
    "# Replace with the actual YouTube video URL (under 30 seconds recommended for testing)\n",
    "video_url = \"YOUTUBE_VIDEO_URL_HERE\"\n",
    "\n",
    "# Output directory structure\n",
    "output_dir = \"output\"\n",
    "img_dir = os.path.join(output_dir, \"img\")\n",
    "data_dir = os.path.join(output_dir, \"data\")\n",
    "\n",
    "# Model name (e.g., 'sam_l.pt', 'sam_b.pt')\n",
    "# Ensure this model file is available or can be downloaded by ultralytics\n",
    "model_name = 'sam_b.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "# Create output directories\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Load the SAM-2 model\n",
    "try:\n",
    "    # Initialize the SAM model\n",
    "    model = SAM(model_name)\n",
    "    print(f\"Successfully loaded model: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model '{model_name}'. Ensure the file exists or is accessible.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    # Exit or handle the error appropriately if running as a script\n",
    "    raise e\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Download Video and Extract Frames ---\n",
    "import yt_dlp\n",
    "\n",
    "print(f\"Downloading video from: {video_url}\")\n",
    "\n",
    "# Download video to a temporary file\n",
    "video_filename = \"temp_video.mp4\"\n",
    "ydl_opts = {\n",
    "    'format': 'best[height<=720]',  # Download reasonable quality to save time\n",
    "    'outtmpl': video_filename,\n",
    "}\n",
    "\n",
    "try:\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "    print(f\"Video downloaded successfully as: {video_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading video: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Extract frames from the downloaded video\n",
    "cap = cv2.VideoCapture(video_filename)\n",
    "frame_count = 0\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f\"Video info: {total_frames} frames at {fps:.2f} FPS\")\n",
    "print(\"Extracting frames...\")\n",
    "\n",
    "# Extract every frame (you can modify this to extract every Nth frame if needed)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    frame_number_str = f\"{frame_count:03d}\"\n",
    "    \n",
    "    # Save frame as image\n",
    "    img_path = os.path.join(img_dir, f\"frame_{frame_number_str}.png\")\n",
    "    cv2.imwrite(img_path, frame)\n",
    "    \n",
    "    if frame_count % 10 == 0:  # Print progress every 10 frames\n",
    "        print(f\"Extracted frame {frame_count}/{total_frames}\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Clean up the temporary video file\n",
    "os.remove(video_filename)\n",
    "\n",
    "print(f\"\\nFrame extraction completed!\")\n",
    "print(f\"Total frames extracted: {frame_count}\")\n",
    "print(f\"Images saved to: {img_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b286ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 2: Run SAM Predictions on Extracted Frames ---\n",
    "# import glob\n",
    "\n",
    "# print(\"Running SAM predictions on extracted frames...\")\n",
    "\n",
    "# # Get list of all extracted frame images\n",
    "# frame_files = sorted(glob.glob(os.path.join(img_dir, \"frame_*.png\")))\n",
    "# total_files = len(frame_files)\n",
    "\n",
    "# print(f\"Found {total_files} frames to process\")\n",
    "\n",
    "# for i, img_path in enumerate(frame_files):\n",
    "#     # Extract frame number from filename\n",
    "#     frame_filename = os.path.basename(img_path)\n",
    "#     frame_number_str = frame_filename.replace(\"frame_\", \"\").replace(\".png\", \"\")\n",
    "    \n",
    "#     print(f\"Processing frame {i+1}/{total_files}: {frame_filename}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Run SAM prediction on the image\n",
    "#         results = model.predict(source=img_path, save=False, save_json=False)\n",
    "        \n",
    "#         # results is a list containing one Results object for the image\n",
    "#         if not results:\n",
    "#             print(f\"  Warning: No results for {frame_filename}\")\n",
    "#             # Create empty JSON file\n",
    "#             json_data = []\n",
    "#         else:\n",
    "#             frame_results = results[0]  # Get the Results object\n",
    "#             json_data = []  # List to hold segmentation data for this frame\n",
    "            \n",
    "#             # Check if segmentation masks are present in the results\n",
    "#             if hasattr(frame_results, 'masks') and frame_results.masks is not None:\n",
    "#                 masks = frame_results.masks\n",
    "                \n",
    "#                 # Extract polygon segments\n",
    "#                 if hasattr(masks, 'segments') and masks.segments is not None:\n",
    "#                     segments_list_np = masks.segments\n",
    "#                     num_segments = len(segments_list_np)\n",
    "#                     print(f\"  Found {num_segments} segments\")\n",
    "                    \n",
    "#                     for j in range(num_segments):\n",
    "#                         segment_np = segments_list_np[j]\n",
    "#                         if segment_np is not None:\n",
    "#                             # Convert the numpy polygon array to a list for JSON\n",
    "#                             polygon_coords = segment_np.tolist()\n",
    "                            \n",
    "#                             segment_info = {\n",
    "#                                 \"polygon\": polygon_coords\n",
    "#                             }\n",
    "#                             json_data.append(segment_info)\n",
    "#                 else:\n",
    "#                     print(f\"  No segments found for {frame_filename}\")\n",
    "#             else:\n",
    "#                 print(f\"  No masks found for {frame_filename}\")\n",
    "        \n",
    "#         # Save the JSON data for the frame\n",
    "#         json_path = os.path.join(data_dir, f\"frame_{frame_number_str}.json\")\n",
    "#         with open(json_path, 'w') as f:\n",
    "#             json.dump(json_data, f, indent=4)\n",
    "            \n",
    "#         print(f\"  Saved segmentation data to: frame_{frame_number_str}.json\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"  Error processing {frame_filename}: {e}\")\n",
    "#         # Create empty JSON file for failed frames\n",
    "#         json_data = []\n",
    "#         json_path = os.path.join(data_dir, f\"frame_{frame_number_str}.json\")\n",
    "#         with open(json_path, 'w') as f:\n",
    "#             json.dump(json_data, f, indent=4)\n",
    "\n",
    "# print(f\"\\nSAM prediction completed!\")\n",
    "# print(f\"Segmentation data saved to: {data_dir}\")\n",
    "# print(f\"You can now inspect the results in the {output_dir} directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e721e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ultralytics.com/models/sam/#sam-comparison-vs-yolo\n",
    "# https://docs.ultralytics.com/datasets/segment/#ultralytics-yolo-format\n",
    "from ultralytics.data.annotator import auto_annotate\n",
    "\n",
    "auto_annotate(\n",
    "    data=img_dir,\n",
    "    det_model=\"yolo11x.pt\",\n",
    "    # sam_model=\"sam_b.pt\", # sam base model; a bit slow on mac...\n",
    "    sam_model=\"mobile_sam.pt\",  # mobile sam model; faster on mac\n",
    "    # max_det=10,\n",
    "    output_dir=data_dir,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
